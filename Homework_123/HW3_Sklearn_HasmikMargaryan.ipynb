{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouC6teuHmxmQ"
      },
      "source": [
        "’ç’ø’∏÷Ä÷á ’£÷Ä’æ’°’Æ ’°’º’°’ª’°’§÷Ä’°’∂÷Ñ’∂’•÷Ä’® ’Ø’°’ø’°÷Ä’•’¨’∏÷Ç ’æ’•÷Ä’ª’∂’°’™’°’¥’Ø’•’ø’® **02.04.2023 23:59** ’ß÷â ‘±’º’°’ª’°’§÷Ä’°’∂÷Ñ’∂’•÷Ä’® ’Ø’°’ø’°÷Ä’•’¨’∏÷Ç÷Å ’∞’•’ø’∏, ’∫’•’ø÷Ñ ’ß \n",
        "\n",
        "1. ’∂’•÷Ä’¢’•’º’∂’•÷Ñ ’°’µ’Ω ÷Ü’°’µ’¨’® ’±’•÷Ä ’∞’°’¥’°’Ø’°÷Ä’£’´’π (`File` $\\to$ `Download .ipynb`)\n",
        "2. ’æ’•÷Ä’∂’°’£÷Ä’´’∂ ’°’æ’•’¨’°÷Å’∂’•÷Ñ ’±’•÷Ä ’°’∂’∏÷Ç’∂, ’°’¶’£’°’∂’∏÷Ç’∂’® ’¨’°’ø’´’∂’°’ø’°’º, ÷Ö÷Ä’´’∂’°’Ø’ù *HW3_Sklearn_NshanPotikyan.ipynb* ÷Ü’∏÷Ä’¥’°’ø’∏’æ\n",
        "3. ’∏÷Ç’≤’°÷Ä’Ø’•÷Ñ ÷Ü’°’µ’¨’® **nshan.potikyan@gmail.com** ’∞’°’Ω÷Å’•’´’∂` ’∂’°’¥’°’Ø’´ ’©’•’¥’° (subject) ’§’°’∑’ø’∏÷Ç’¥ ’£÷Ä’•’¨’∏’æ **HA3**\n",
        "\n",
        "**’à÷Ç’∑’°’§÷Ä’∏÷Ç’©’µ’∏÷Ç’∂**‚Ä§ \n",
        "1. ’é’•÷Ä’∏’∂’∑’µ’°’¨ ’∫’°’µ’¥’°’∂’∂’•÷Ä’´’∂ ’π’¢’°’æ’°÷Ä’°÷Ä’•’¨’∏÷Ç ’§’•’∫÷Ñ’∏÷Ç’¥ ’±’•÷Ä ’°’∑’≠’°’ø’°’∂÷Ñ’® ’π’´ ’£’∂’°’∞’°’ø’æ’´÷â\n",
        "2. **numpy**, **pandas** ÷á **sklearn**  ’£÷Ä’°’§’°÷Ä’°’∂’∂’•÷Ä’´÷Å ’¢’°÷Å’´ ’°’µ’¨ ’£÷Ä’°’§’°÷Ä’°’∂’∂’•÷Ä’´÷Å ’π’´’õ ’Ø’°÷Ä’•’¨’´ ÷Ö’£’ø’æ’•’¨ \n",
        "3. ‘ø’∏’§’´ ’∞’°’¥’°÷Ä ’∂’°’≠’°’ø’•’Ω’æ’°’Æ ’∞’°’æ’•’¨’µ’°’¨ ’æ’°’∂’§’°’Ø’∂’•÷Ä ’Ω’ø’•’≤’Æ’•’¨ ’∂’∏÷Ç’µ’∂’∫’•’Ω ’π’´ ’Ø’°÷Ä’•’¨’´ \n",
        "4. ’Ñ’•’Ø ‚≠ê-’® ’¥’•’Ø ’¥’´’°’æ’∏÷Ä (’∞’°÷Ä’°’¢’•÷Ä’°’Ø’°’∂) ’ß  \n",
        "5. ’Ü’∏÷Ä’´÷Å ’Ø’°÷Ä’§’°’¨ 1., 2. ÷á 3. ’Ø’•’ø’•÷Ä’®\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "’Ü’•÷Ä÷Ñ’∏’∂’∑’µ’°’¨ ’æ’°’∂’§’°’Ø’® ’°’∑’≠’°’ø’°÷Å’∂’•’¨’∏÷Ç ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∏÷Ç’¥ ’Ø’∂’•÷Ä’¥’∏÷Ç’Æ’æ’•’∂ ’°’∂’∞÷Ä’°’™’•’∑’ø ’£÷Ä’°’§’°÷Ä’°’∂’∂’•÷Ä ÷á ’ø’æ’µ’°’¨’∂’•÷Ä÷â "
      ],
      "metadata": {
        "id": "2llMXDU2vhmS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Vn0GtnroyLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8245635f-c0c0-4f49-bcb9-bfd74d999c39"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "titanic = fetch_openml(name='Titanic', version=1)\n",
        "titanic = pd.concat([titanic['data'], titanic['target']], axis=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WbPDB3mI7MO"
      },
      "source": [
        "**‘Ω’∂’§’´÷Ä 1.‚≠ê‚≠ê** ‘±’µ’Ω ÷á ’∞’°’ª’∏÷Ä’§ ’≠’∂’§’´÷Ä’∂’•÷Ä’´ ’∂’∫’°’ø’°’Ø’∂ ’°’µ’∂ ’ß’ù ’´ ’æ’•÷Ä’ª’∏ ’Ø’°’º’∏÷Ç÷Å’•’∂÷Ñ ’°’µ’∂’∫’´’Ω’´ ’°’¨’£’∏÷Ä’´’©’¥, ’∏÷Ä’´ ’¥’´’ª’∏÷Å’∏’æ ’Ø’°÷Ä’•’¨’´ ’ß *’Ø’°’∂’≠’°’ø’•’Ω’•’¨* ’°÷Ä’§’µ’∏÷Ñ ’ø÷Ä’æ’°’Æ ’∞’°’ø’Ø’°’∂’´’∑’∂’•÷Ä’∏’æ ’¥’°÷Ä’§’® ’∏’≤’ª ’Ø’¥’∂’°÷Ä ’è’´’ø’°’∂’´’Ø ’∂’°’æ’´ ’≠’∏÷Ä’ø’°’Ø’¥’°’∂ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∏÷Ç’¥, ’©’• ’∏’π÷â \n",
        "\n",
        "‘±’µ’Ω ’≠’∂’§÷Ä’∏÷Ç’¥ ’∫’°’∞’°’∂’ª’æ’∏÷Ç’¥ ’ß ’¨÷Ä’°÷Å’∂’•’¨ ``function1`` ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’∂ ’°’µ’∂’∫’•’Ω, ’∏÷Ä \n",
        "\n",
        "* ’®’∂’§’∞’°’∂’∏÷Ç÷Ä **titanic** ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’¥’∏÷Ç’©’µ’∏÷Ç’∂’´÷Å ’¥’∂’°’∂ ’¥’´’°’µ’∂ **pclass**, **sex**, **age**, **survived** ’Ω’µ’∏÷Ç’∂’•÷Ä’´ ’ø’æ’µ’°’¨’∂’•÷Ä’®, \n",
        "* **sex** ’Ω’µ’°’∂ ’°’∂’∏÷Ç’∂’® ’§’°’º’∂’° **male** ÷á ’∫’°÷Ä’∏÷Ç’∂’°’Ø’´ ’©’æ’°’µ’´’∂ ’ø’æ’µ’°’¨’∂’•÷Ä (female -> 0, male -> 1): ’è’•’õ’Ω [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder) ’Ø’¨’°’Ω’®÷â \n",
        "* ’Ω’ø’°÷Å’æ’°’Æ ’ø’æ’µ’°’¨’∂’•÷Ä’® ’≠’°’º’∂’•’¨’∏÷Ç÷Å ’∞’•’ø’∏ ’¢’°’™’°’∂’æ’•’∂ train (80%), test (20%) ’¥’°’Ω’•÷Ä’´’ù ÷Ö’£’ø’°’£’∏÷Ä’Æ’•’¨’∏’æ sklearn ’£÷Ä’°’§’°÷Ä’°’∂’´ [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)  ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’∂ ``random_state=0`` ’∫’°÷Ä’°’¥’•’ø÷Ä’∏’æ÷â  ’ñ’∏÷Ç’∂’Ø÷Å’´’°’µ’´ ’°’∑’≠’°’ø’°’∂÷Ñ’´ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∏÷Ç’¥ ’∫’•’ø÷Ñ ’ß ’Ω’ø’°÷Å’æ’•’∂ 4 ’∞’°’ø ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’¥’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä \n",
        "* X_train (pandas.DataFrame)\n",
        "* X_test (pandas.DataFrame)\n",
        "* y_train (pandas.Series)\n",
        "* y_test (pandas.Series)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def function1(data):\n",
        "  # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "   data = data[['pclass', 'sex', 'age', 'survived']].copy()\n",
        "\n",
        "   encoder = OrdinalEncoder(categories=[['female', 'male']])\n",
        "   data['sex'] = encoder.fit_transform(data[['sex']])\n",
        "    \n",
        "   X, y = data.drop(columns=['survived']), data['survived']\n",
        "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "    \n",
        "   return X_train,X_test,y_train,y_test"
      ],
      "metadata": {
        "id": "2V9dAiZOqhOy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTN0Ve60jEqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452f22e0-b110-4246-f74c-aa98625b2243"
      },
      "source": [
        "# ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’•÷Ñ ’Ω’ø’∏÷Ç’£’•’¨ ’±’•÷Ä ’¨’∏÷Ç’Æ’∏÷Ç’¥’®\n",
        "X_train, X_test, y_train, y_test = function1(data=titanic)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1047, 3)\n",
            "(262, 3)\n",
            "(1047,)\n",
            "(262,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‘Ω’∂’§’´÷Ä 2.‚≠ê‚≠ê** ‘µ’©’• ’∂’Ø’°’ø’•÷Å’´÷Ñ (’•’©’• ’π’ß, ’∂’Ø’°’ø’•÷Ñ üëÄ) ’∂’°’≠’∏÷Ä’§ ’≠’∂’§÷Ä’∏÷Ç’¥ ’Ω’ø’°÷Å’æ’°’Æ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¥’•’ª ’Ø’°’∂ ’¢’°÷Å’°’Ø’°’µ’∏’≤ ’°÷Ä’™’•÷Ñ’∂’•÷Ä÷â \n",
        "\n",
        "‘±’µ’Ω ’≠’∂’§÷Ä’∏÷Ç’¥ ’∫’°’∞’°’∂’ª’æ’∏÷Ç’¥ ’ß ’£÷Ä’•’¨ ’°’µ’∂’∫’´’Ω’´  ``function2`` ’°’∂’∏÷Ç’∂’∏’æ ÷Ü’∏÷Ç’∂’Ø÷Å’´’°, ’∏÷Ä’® ’Ø’¨÷Ä’°÷Å’∂’´ ’°’µ’§ ’¢’°÷Å’°’Ø’°’µ’∏’≤ ’ø’æ’µ’°’¨’∂’•÷Ä’®’ù ÷Ö’£’ø’°’£’∏÷Ä’Æ’•’¨’∏’æ [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) ’Ø’¨’°’Ω’®, ’´’Ω’Ø strategy ÷É’∏÷É’∏’≠’°’Ø’°’∂’® ’Ø’ø÷Ä’æ’´ ``function2`` ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’µ’´ ’¥’´’ª’∏÷Å’∏’æ÷â \n",
        "\n",
        "‘±’µ’Ω ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’µ’´ ’°’∑’≠’°’ø’°’∂÷Ñ’´ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∏÷Ç’¥ ’∫’•’ø÷Ñ ’ß ’Ω’ø’•’≤’Æ’æ’•’∂ ’∂’°’≠’∏÷Ä’§ ’≠’∂’§÷Ä’∏÷Ç’¥ ’¢’°÷Å’°’Ø’°’µ’∏’≤ ’°÷Ä’™’•÷Ñ’∂’•÷Ä ’∏÷Ç’∂’•÷Å’∏’≤ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’¥’∏÷Ç’©’µ’∏÷Ç’∂’∂’•÷Ä’´ ’Ø÷Ä’Ø’∂÷Ö÷Ä’´’∂’°’Ø’∂’•÷Ä (copy)÷â"
      ],
      "metadata": {
        "id": "F1TFnw9fcgch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def function2(X_train, X_test, y_train, y_test, strategy):\n",
        "  # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "  imputer = SimpleImputer(missing_values=np.nan,strategy=strategy)\n",
        "  X_train = imputer.fit_transform(X_train)\n",
        "  X_test = imputer.transform(X_test)\n",
        "  \n",
        "  return X_train,X_test,y_train,y_test"
      ],
      "metadata": {
        "id": "rqBL-n2beFkn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’•÷Ñ ’Ω’ø’∏÷Ç’£’•’¨ ’±’•÷Ä ’¨’∏÷Ç’Æ’∏÷Ç’¥’®\n",
        "X_train_, X_test_, y_train_, y_test_ = function2(X_train, X_test, y_train, y_test,\n",
        "                                             strategy='mean')\n",
        "print(np.isnan(X_train_).sum())\n",
        "print(np.isnan(X_test_).sum())"
      ],
      "metadata": {
        "id": "YDDA8NdDeGbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798549c0-bcf9-4772-ab9e-0fe1d8506724"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‘Ω’∂’§’´÷Ä 3.‚≠ê‚≠ê‚≠ê** ’Ü’°’≠’∏÷Ä’§ ’§’°’Ω’´ ’®’∂’©’°÷Å÷Ñ’∏÷Ç’¥ ’ø’•’Ω’°’∂÷Ñ, ’©’• ’´’∂’π’∫’•’Ω ’Ø’°÷Ä’•’¨’´ ’ß ’Ω’ø’•’≤’Æ’•’¨/’°’æ’•’¨’°÷Å’∂’•’¨ ’∂’∏÷Ä ’°’¨’£’∏÷Ä’´’©’¥ sklearn ’£÷Ä’°’§’°÷Ä’°’∂’´ Estimator ’Ø’¨’°’Ω’´ ’∞’´’¥÷Ñ’´ ’æ÷Ä’°÷â ‘±’µ’Ω ’≠’∂’§÷Ä’∏÷Ç’¥ ’∫’°’∞’°’∂’ª’æ’∏÷Ç’¥ ’ß ’Ω’ø’•’≤’Æ’•’¨ **BasicLinearClassifier** ’°’∂’∏÷Ç’∂’∏’æ multi-class ’§’°’Ω’°’Ø’°÷Ä’£’¥’°’∂ ’¥’∏’§’•’¨ (’∏÷Ä’∫’•’Ω ``class``), ’∏÷Ä’® ’°’∑’≠’°’ø’∏÷Ç’¥ ’ß ’∞’•’ø÷á’µ’°’¨ ’Ø’•÷Ä’∫‚Ä§\n",
        "\n",
        "* ’∏÷Ç’Ω’∏÷Ç÷Å’°’∂’¥’°’∂ ’®’∂’©’°÷Å÷Ñ’∏÷Ç’¥ ’∏÷Ç’Ω’∏÷Ç÷Å’∏’≤’°’Ø’°’∂ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¢’°’¶’¥’∏÷Ç’©’µ’°’∂ (training data) ’æ÷Ä’° ’µ’∏÷Ç÷Ä’°÷Ñ’°’∂’π’µ’∏÷Ç÷Ä ’§’°’Ω’´ (class/label) ’∞’°’¥’°÷Ä ’∞’°’∑’æ’°÷Ä’Ø’æ’∏÷Ç’¥ ’ß ’°’µ’§ ’§’°’Ω’´ **’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π÷ä’æ’•’Ø’ø’∏÷Ä**\n",
        "\n",
        "* ’Ø’°’∂’≠’°’ø’•’Ω’¥’°’∂ (prediction/inference) ’™’°’¥’°’∂’°’Ø ’∞’°’∑’æ’°÷Ä’Ø’æ’∏÷Ç’¥ ’ß ’µ’∏÷Ç÷Ä’°÷Ñ’°’∂’π’µ’∏÷Ç÷Ä ’Ω’ø’∏÷Ç’£’∏’≤’°’Ø’°’∂ ’ø’æ’µ’°’¨’´ ’∞’•’º’°’æ’∏÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’® ’¢’∏’¨’∏÷Ä ’§’°’Ω’•÷Ä’´ ’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π-’æ’•’Ø’ø’∏÷Ä’∂’•÷Ä’´ ’∂’Ø’°’ø’¥’°’¥’¢ ÷á ’∏÷Ä’∫’•’Ω ’Ø’°’∂’≠’°’ø’•’Ω’∏÷Ç’¥ ’®’∂’ø÷Ä’æ’∏÷Ç’¥ ’ß ’°’µ’∂ ’§’°’Ω’®, ’∏÷Ä’´ ’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π-’æ’•’Ø’ø’∏÷Ä’® ’°’¥’•’∂’°’¥’∏’ø’∂ ’ß ’Ω’ø’∏÷Ç’£’∏’≤’°’Ø’°’∂ ’ø’æ’µ’°’¨’´’∂\n",
        "\n",
        "* ’°’¨’£’∏÷Ä’´’©’¥’® ’∫’•’ø÷Ñ ’ß ’∏÷Ç’∂’•’∂’° 2 ’∞’´’∫’•÷Ä÷ä’∫’°÷Ä’°’¥’•’ø÷Ä \n",
        "  * **class_representative**: ’Ø’°÷Ä’∏’≤ ’ß ’®’∂’§’∏÷Ç’∂’•’¨ *mean* ’Ø’°’¥ *median* ’°÷Ä’™’•÷Ñ’®, ’∏÷Ä’´÷Å ’Ø’°’≠’æ’°’Æ ’Ø’∏÷Ä’∏’∑’æ’´ ’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π-’æ’•’Ø’ø’∏÷Ä’´ ’∞’°’∑’æ’°÷Ä’Ø’¥’°’∂ ’Ø’°÷Ä’£’®, ’°’µ’Ω’´’∂÷Ñ’∂’ù mean-’´ ’§’•’∫÷Ñ’∏÷Ç’¥ ’µ’∏÷Ç÷Ä’°÷Ñ’°’∂’π’µ’∏÷Ç÷Ä ’§’°’Ω’´ ’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π-’æ’•’Ø’ø’∏÷Ä’® ’Ø’¨’´’∂’´ ’°’µ’§ ’§’°’Ω’´’∂ ’∫’°’ø’Ø’°’∂’∏’≤ ’ø’æ’µ’°’¨’∂’•÷Ä’´ ’¥’´’ª’´’∂’®, ’´’Ω’Ø median-’´ ’§’•’∫÷Ñ’∏÷Ç’¥’ù ’¥’•’§’´’°’∂ ’æ’•’Ø’ø’∏÷Ä’®÷â \n",
        "  * **distance**: ’Ø’°÷Ä’∏’≤ ’ß ’®’∂’§’∏÷Ç’∂’•’¨ *L1* ’Ø’°’¥ *L2*, ’∏÷Ä’´÷Å ’Ø’°’≠’æ’°’Æ ’Ø’Ω’°’∞’¥’°’∂’æ’´ ’Ø’°’¥’°’µ’°’Ø’°’∂ ’ø’æ’µ’°’¨’´ ÷á ’∂’•÷Ä’Ø’°’µ’°÷Å’∏÷Ç÷Å’´’π-’æ’•’Ø’ø’∏÷Ä’´ ’¥’´’ª÷á ’•’≤’°’Æ ’∞’•’º’°’æ’∏÷Ä’∏÷Ç’©’µ’∏÷Ç’∂’®‚Ä§ L1-’´ ’§’•’∫÷Ñ’∏÷Ç’¥ ’®’Ω’ø ‘º1 ’∂’∏÷Ä’¥’´, ’´’Ω’Ø L2-’´ ’§’•’∫÷Ñ’∏÷Ç’¥ ’®’Ω’ø ‘º2 ’∂’∏÷Ä’¥’´÷â "
      ],
      "metadata": {
        "id": "wahYpxE0mA_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.estimator_checks import check_estimator, check_is_fitted\n",
        "from sklearn.utils.validation import check_X_y, check_array\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "# ’°’µ’Ω’ø’•’≤ ’Ø’°÷Ä’•’¨’´ ’ß ’∂’•÷Ä’¥’∏÷Ç’Æ’•’¨ ’°’µ’¨ ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’∂’•÷Ä\n",
        "\n",
        "class BasicLinearClassifier(ClassifierMixin, BaseEstimator):\n",
        "  \"\"\"\n",
        "  Basic Linear Classifier\n",
        "  for multi-class classification case.\n",
        "  \"\"\"\n",
        "  def __init__(self, class_representative='mean', distance='L2'):\n",
        "    # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "    self.class_representative = class_representative\n",
        "    self.distance=distance\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\"\n",
        "    Fits the model on given data, which in this case means \n",
        "    calculating the class means/medians and storing them\n",
        "    for later usage in 'predict' method.\n",
        "\n",
        "    :param numpy.ndarray X: input data of size (nr_samples, nr_features)\n",
        "    :param numpy.ndarray y: labels of size (nr_data_points,)\n",
        "    \"\"\"\n",
        "    # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "\n",
        "    X,y = check_X_y(X,y)\n",
        "\n",
        "    self.classes_ = unique_labels(y)\n",
        "    self.n_features_in_ = X.shape[1]\n",
        "    self.representative_ = []\n",
        "    for i in range(len(self.classes_)):\n",
        "      c = self.classes_[i]\n",
        "      if self.class_representative == \"mean\":\n",
        "        self.representative_.append(np.mean(X[y==c],axis = 0))\n",
        "      elif self.class_representative == \"median\":\n",
        "        self.representative_.append(np.median(X[y==c],axis = 0))\n",
        "      else:\n",
        "        raise ValueError(\"class_representative must be 'mean' or 'median'\")\n",
        "    return self\n",
        "  \n",
        "  def predict(self, X):\n",
        "    \"\"\"\n",
        "    Performs predictions on the given data points\n",
        "    using the estimated class means/medians.\n",
        "\n",
        "    :param numpy.ndarray X: input data for testing (nr_samples, nr_features)\n",
        "    :returns: labels of size (nr_samples,)\n",
        "    :rtype: numpy.ndarray or pandas.Series\n",
        "    \"\"\"\n",
        "    # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "    \n",
        "    check_is_fitted(self)\n",
        "    X = check_array(X)\n",
        "\n",
        "    distances = []\n",
        "    for x in X:\n",
        "      temp = []\n",
        "      for j in range(len(self.classes_)):\n",
        "        if self.distance == 'L1':\n",
        "          temp.append(np.sum(np.abs(x - self.representative_[j])))\n",
        "        elif self.distance == 'L2':\n",
        "          temp.append(np.sqrt(np.sum(np.square(x - self.representative_[j]))))\n",
        "        else:\n",
        "          raise ValueError(\"distance must be 'L1' or 'L2'\")\n",
        "      distances.append(temp)\n",
        "    distances = np.array(distances)\n",
        "    return self.classes_[np.argmin(distances, axis=1)]"
      ],
      "metadata": {
        "id": "ojkWS9GBQJvn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’•÷Ñ ’Ω’ø’∏÷Ç’£’•’¨ ’±’•÷Ä ’¨’∏÷Ç’Æ’∏÷Ç’¥’®\n",
        "model = BasicLinearClassifier()\n",
        "check_estimator(model)\n",
        "model.fit(X_train_, y_train_)\n",
        "model.score(X_test_, y_test_)"
      ],
      "metadata": {
        "id": "n8LN7pugPizp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49428ed-0adf-4d98-df9a-a8b035809ef3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5916030534351145"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‘Ω’∂’§’´÷Ä 4.‚≠ê‚≠ê‚≠ê** ‘±’µ’Ω ’≠’∂’§÷Ä’∏÷Ç’¥ ’∫’°’∞’°’∂’ª’æ’∏÷Ç’¥ ’ß ’¨÷Ä’°÷Å’∂’•’¨ ``function4`` ’°’∂’∏÷Ç’∂’∏’æ ÷Ü’∏÷Ç’∂’Ø÷Å’´’°, ’∏÷Ä’´ ’∂’•÷Ä’Ω’∏÷Ç’¥ ’Ø’Ø’°’º’∏÷Ç÷Å’æ’´ SimpleImputer-’´÷Å ÷á BasicLinearClassifier÷ä’´÷Å ’¢’°’≤’Ø’°÷Å’°’Æ sklearn Pipeline ÷á ’Ø’´÷Ä’°’Ø’°’∂’°÷Å’æ’´ GridSearch (cv=5) ’∞’•’ø÷á’µ’°’¨ ’∫’°÷Ä’°’¥’•’ø÷Ä’•÷Ä’´ ’æ÷Ä’°’µ’∏’æ’ù\n",
        "\n",
        "* SimpleImputer\n",
        "  * strategy = ['mean', 'median', 'most_frequent']\n",
        "* BasicLinearClassifier\n",
        "  * class_representative = ['mean', 'median']\n",
        "  * distance = ['L1', 'L2']:\n",
        "\n",
        "’ñ’∏÷Ç’∂’Ø÷Å’´’°’∂ ’∫’•’ø÷Ñ ’ß ’æ’•÷Ä’°’§’°÷Ä’±’∂’´ GridSearchCV-’´÷Å ’Ω’ø’•’≤’Æ’æ’°’Æ ÷Ö’¢’µ’•’Ø’ø’´ cv_results_ ’¢’∂’∏÷Ç’©’°’£÷Ä’´’π’® (attribute) ’∏÷Ä’∫’•’Ω pandas.DataFrame: ‘±’µ’Ω ÷Ü’∏÷Ç’∂’Ø÷Å’´’°’µ’´’∂ ’∫’•’ø÷Ñ ’ß ’ø’°’¨ ‘Ω’∂’§’´÷Ä 1÷ä’´ ’°÷Ä’§’µ’∏÷Ç’∂÷Ñ’∏÷Ç’¥ ’Ω’ø’°÷Å’æ’°’Æ ’∏÷Ç’Ω’∏÷Ç÷Å’∏’≤’°’Ø’°’∂ ’ø’æ’µ’°’¨’∂’•÷Ä’®÷â"
      ],
      "metadata": {
        "id": "TrGM0EzrWrt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import  make_pipeline\n",
        "\n",
        "def function4(X_train, y_train):\n",
        "  # ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’ß ’¨’´’∂’•’¨ ’±’•÷Ä ’Ø’∏’§’®\n",
        "  pipe = make_pipeline(SimpleImputer(),\n",
        "                     BasicLinearClassifier())\n",
        "\n",
        "  params = {'simpleimputer__strategy':['mean', 'median', 'most_frequent'],\n",
        "          'basiclinearclassifier__class_representative' :['mean', 'median'],\n",
        "          'basiclinearclassifier__distance': ['L1', 'L2']\n",
        "             }\n",
        "\n",
        "  grid = GridSearchCV(pipe,param_grid=params,cv=5)\n",
        "  grid.fit(X_train, y_train)\n",
        "\n",
        "  return pd.DataFrame(grid.cv_results_)"
      ],
      "metadata": {
        "id": "18oLxQzCWzES"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‘±’µ’Ω’ø’•’≤ ’Ø’°÷Ä’∏’≤ ’•÷Ñ ’Ω’ø’∏÷Ç’£’•’¨ ’±’•÷Ä ’¨’∏÷Ç’Æ’∏÷Ç’¥’®\n",
        "print(function4(X_train, y_train).head())"
      ],
      "metadata": {
        "id": "oDGec5MEdir_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69006627-3cc5-4762-db38-2f830c759b53"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
            "0       0.008437      0.002760         0.006764        0.001737   \n",
            "1       0.004510      0.000096         0.004565        0.000052   \n",
            "2       0.005027      0.000315         0.004734        0.000234   \n",
            "3       0.004268      0.000254         0.005308        0.000060   \n",
            "4       0.004755      0.000599         0.006386        0.001848   \n",
            "\n",
            "  param_basiclinearclassifier__class_representative  \\\n",
            "0                                              mean   \n",
            "1                                              mean   \n",
            "2                                              mean   \n",
            "3                                              mean   \n",
            "4                                              mean   \n",
            "\n",
            "  param_basiclinearclassifier__distance param_simpleimputer__strategy  \\\n",
            "0                                    L1                          mean   \n",
            "1                                    L1                        median   \n",
            "2                                    L1                 most_frequent   \n",
            "3                                    L2                          mean   \n",
            "4                                    L2                        median   \n",
            "\n",
            "                                              params  split0_test_score  \\\n",
            "0  {'basiclinearclassifier__class_representative'...           0.738095   \n",
            "1  {'basiclinearclassifier__class_representative'...           0.733333   \n",
            "2  {'basiclinearclassifier__class_representative'...           0.714286   \n",
            "3  {'basiclinearclassifier__class_representative'...           0.685714   \n",
            "4  {'basiclinearclassifier__class_representative'...           0.609524   \n",
            "\n",
            "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
            "0           0.761905           0.492823           0.712919           0.703349   \n",
            "1           0.757143           0.401914           0.698565           0.698565   \n",
            "2           0.719048           0.693780           0.741627           0.693780   \n",
            "3           0.542857           0.478469           0.521531           0.564593   \n",
            "4           0.580952           0.401914           0.425837           0.559809   \n",
            "\n",
            "   mean_test_score  std_test_score  rank_test_score  \n",
            "0         0.681818        0.096676                6  \n",
            "1         0.657904        0.129904                7  \n",
            "2         0.712504        0.017862                5  \n",
            "3         0.558633        0.069623               10  \n",
            "4         0.515607        0.084887               12  \n"
          ]
        }
      ]
    }
  ]
}